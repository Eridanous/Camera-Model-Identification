{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'sample_submission.csv', 'train']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation,Dropout,BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = '../input/'\n",
    "train_files = sorted(glob.glob(data + 'train/*/*'))\n",
    "# test_path = sorted(glob.glob(data + 'test/*'))\n",
    "\n",
    "labels = ['HTC-1-M7', 'iPhone-4s', 'iPhone-6', 'LG-Nexus-5x', 'Motorola-Droid-Maxx', \n",
    "         'Motorola-Nexus-6', 'Motorola-X', 'Samsung-Galaxy-Note3', 'Samsung-Galaxy-S4',\n",
    "         'Sony-NEX-7'] \n",
    "All_labels = [labels.index(file.split('/')[-2]) for file in train_files] # TO BE CHANGED!!!!!!!\n",
    "\n",
    "x_train_files, x_test_files, y_train_files, y_test_files = train_test_split(train_files,All_labels,test_size = 0.2, shuffle = True,random_state = 42)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train_files, len(labels)) # one hot vector\n",
    "y_test = keras.utils.to_categorical(y_test_files, len(labels)) # one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a55df51c3f6cc910977567a4ea61581d8981a774"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b3bd3df380430aa1b8dfeda201b12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 256\n",
    "\n",
    "train_imgs = []\n",
    "for file in tqdm_notebook(x_train_files):\n",
    "    img = cv2.imread(file)\n",
    "    center_x = img.shape[0]//2\n",
    "    center_y = img.shape[1]//2 \n",
    "\n",
    "    cropped_img = img[center_x-dim//2:center_x+dim//2, center_y-dim//2:center_y+dim//2, : ]\n",
    "    \n",
    "#     cropped_img = cv2.filter2D(cropped_img.astype(np.float32),-1,kernel_filter)\n",
    "    cropped_img = cropped_img.astype(np.float32)\n",
    "    \n",
    "    train_imgs.append(cropped_img)\n",
    "    del file,img,center_x,center_y,cropped_img\n",
    "    gc.collect()\n",
    "\n",
    "train_imgs = np.array(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8a5a77e9406985c267568b761e6fddb53391cfc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "dab100bcc2c10682350243aa7833667184a82e51"
   },
   "outputs": [],
   "source": [
    "def myFunc(img):\n",
    "    kernel_filter = 1/12. * np.array([\\\n",
    "            [-1,  2,  -2,  2, -1],  \\\n",
    "            [ 2, -6,   8, -6,  2],  \\\n",
    "            [-2,  8, -12,  8, -2],  \\\n",
    "            [ 2, -6,   8, -6,  2],  \\\n",
    "            [-1,  2,  -2,  2, -1]])\n",
    "\n",
    "    pro_img = cv2.filter2D(img,-1,kernel_filter)\n",
    "    return pro_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "117d2eef7a1c87ebec472155dd43d563a55c8752"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip = True,preprocessing_function = myFunc)\n",
    "\n",
    "datagen.fit(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "e7f237e3fc41487897d524dc60b01ae4aae754ca"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726547b922754362b688cfca74594adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=550), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 256\n",
    "\n",
    "kernel_filter = 1/12. * np.array([\\\n",
    "            [-1,  2,  -2,  2, -1],  \\\n",
    "            [ 2, -6,   8, -6,  2],  \\\n",
    "            [-2,  8, -12,  8, -2],  \\\n",
    "            [ 2, -6,   8, -6,  2],  \\\n",
    "            [-1,  2,  -2,  2, -1]])\n",
    "\n",
    "\n",
    "test_imgs = []\n",
    "for file in tqdm_notebook(x_test_files):\n",
    "    img = cv2.imread(file)\n",
    "    center_x = img.shape[0]//2\n",
    "    center_y = img.shape[1]//2 \n",
    "    cropped_img = img[center_x-dim//2:center_x+dim//2, center_y-dim//2:center_y+dim//2, : ]\n",
    "    \n",
    "    cropped_img = cv2.filter2D(cropped_img.astype(np.float32),-1,kernel_filter)    \n",
    "    test_imgs.append(cropped_img)\n",
    "    del file,img,center_x,center_y,cropped_img\n",
    "    gc.collect()\n",
    "\n",
    "test_imgs = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e6843fe4a3f1a560aedf56edca1e0892863fbe98"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 0.0001\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "9890c5e4a394ee603554a46ae436e415259031cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 127, 127, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 127, 127, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 63, 63, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 61, 61, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 61, 61, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               7373056   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,524,522\n",
      "Trainable params: 8,524,202\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),strides=(2, 2), input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),strides=(2, 2) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=lr_schedule(0), decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "7342ae76fb08b4ed9980cd52b50e9783e1dc952d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 11s 153ms/step - loss: 2.5587 - acc: 0.1440 - val_loss: 2.1651 - val_acc: 0.1873\n",
      "Epoch 2/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 2.2247 - acc: 0.1567 - val_loss: 2.1635 - val_acc: 0.1636\n",
      "Epoch 3/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 2.1580 - acc: 0.1898 - val_loss: 2.0855 - val_acc: 0.2109\n",
      "Epoch 4/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 2.0157 - acc: 0.2328 - val_loss: 1.8720 - val_acc: 0.2455\n",
      "Epoch 5/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.9005 - acc: 0.2723 - val_loss: 1.7892 - val_acc: 0.3200\n",
      "Epoch 6/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 1.8297 - acc: 0.3009 - val_loss: 1.6874 - val_acc: 0.3509\n",
      "Epoch 7/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.7520 - acc: 0.3060 - val_loss: 1.6373 - val_acc: 0.3709\n",
      "Epoch 8/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.7606 - acc: 0.2976 - val_loss: 1.7006 - val_acc: 0.3418\n",
      "Epoch 9/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.7073 - acc: 0.3216 - val_loss: 1.7201 - val_acc: 0.3182\n",
      "Epoch 10/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 1.6777 - acc: 0.3472 - val_loss: 1.7199 - val_acc: 0.3455\n",
      "Epoch 11/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.6363 - acc: 0.3705 - val_loss: 1.5206 - val_acc: 0.4000\n",
      "Epoch 12/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.6163 - acc: 0.3602 - val_loss: 1.5579 - val_acc: 0.4164\n",
      "Epoch 13/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.5982 - acc: 0.3706 - val_loss: 1.4993 - val_acc: 0.4309\n",
      "Epoch 14/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.5985 - acc: 0.3730 - val_loss: 1.6439 - val_acc: 0.3855\n",
      "Epoch 15/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.5644 - acc: 0.3836 - val_loss: 1.6563 - val_acc: 0.3636\n",
      "Epoch 16/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.5163 - acc: 0.4055 - val_loss: 1.5492 - val_acc: 0.4582\n",
      "Epoch 17/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.5019 - acc: 0.4222 - val_loss: 1.4904 - val_acc: 0.4164\n",
      "Epoch 18/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.4492 - acc: 0.4463 - val_loss: 1.3758 - val_acc: 0.4927\n",
      "Epoch 19/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.4103 - acc: 0.4682 - val_loss: 1.3836 - val_acc: 0.4945\n",
      "Epoch 20/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.3836 - acc: 0.4595 - val_loss: 1.5058 - val_acc: 0.4691\n",
      "Epoch 21/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.3481 - acc: 0.4887 - val_loss: 1.3752 - val_acc: 0.4982\n",
      "Epoch 22/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 1.3346 - acc: 0.4935 - val_loss: 1.3086 - val_acc: 0.5491\n",
      "Epoch 23/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.2642 - acc: 0.5239 - val_loss: 1.3299 - val_acc: 0.5273\n",
      "Epoch 24/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.2503 - acc: 0.5386 - val_loss: 1.5395 - val_acc: 0.4836\n",
      "Epoch 25/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.2114 - acc: 0.5356 - val_loss: 1.3094 - val_acc: 0.5436\n",
      "Epoch 26/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.1865 - acc: 0.5578 - val_loss: 1.1593 - val_acc: 0.5636\n",
      "Epoch 27/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.1455 - acc: 0.5741 - val_loss: 1.0743 - val_acc: 0.6218\n",
      "Epoch 28/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.1069 - acc: 0.5860 - val_loss: 1.4632 - val_acc: 0.4873\n",
      "Epoch 29/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.0855 - acc: 0.5847 - val_loss: 1.0704 - val_acc: 0.6345\n",
      "Epoch 30/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.0905 - acc: 0.6040 - val_loss: 1.3453 - val_acc: 0.5691\n",
      "Epoch 31/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.0823 - acc: 0.5851 - val_loss: 1.1233 - val_acc: 0.5891\n",
      "Epoch 32/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.0305 - acc: 0.6087 - val_loss: 1.6216 - val_acc: 0.5164\n",
      "Epoch 33/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 1.0264 - acc: 0.6110 - val_loss: 0.9688 - val_acc: 0.6345\n",
      "Epoch 34/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 1.0378 - acc: 0.6252 - val_loss: 0.9697 - val_acc: 0.6600\n",
      "Epoch 35/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.9705 - acc: 0.6333 - val_loss: 0.9630 - val_acc: 0.6545\n",
      "Epoch 36/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 118ms/step - loss: 0.9391 - acc: 0.6413 - val_loss: 1.1458 - val_acc: 0.6000\n",
      "Epoch 37/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.9794 - acc: 0.6375 - val_loss: 0.8633 - val_acc: 0.6691\n",
      "Epoch 38/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.9253 - acc: 0.6457 - val_loss: 1.3021 - val_acc: 0.5764\n",
      "Epoch 39/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.9060 - acc: 0.6735 - val_loss: 0.9299 - val_acc: 0.6727\n",
      "Epoch 40/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.9178 - acc: 0.6558 - val_loss: 0.8244 - val_acc: 0.7109\n",
      "Epoch 41/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.8619 - acc: 0.6879 - val_loss: 0.9191 - val_acc: 0.6564\n",
      "Epoch 42/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.8348 - acc: 0.6937 - val_loss: 0.9100 - val_acc: 0.6582\n",
      "Epoch 43/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.8696 - acc: 0.6959 - val_loss: 0.8920 - val_acc: 0.6873\n",
      "Epoch 44/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.8143 - acc: 0.6996 - val_loss: 0.8035 - val_acc: 0.7073\n",
      "Epoch 45/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.7981 - acc: 0.7061 - val_loss: 0.8575 - val_acc: 0.7291\n",
      "Epoch 46/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.7946 - acc: 0.6990 - val_loss: 0.7956 - val_acc: 0.7055\n",
      "Epoch 47/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.7807 - acc: 0.7021 - val_loss: 0.8399 - val_acc: 0.6764\n",
      "Epoch 48/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.7861 - acc: 0.7159 - val_loss: 1.0632 - val_acc: 0.6564\n",
      "Epoch 49/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 118ms/step - loss: 0.7816 - acc: 0.7242 - val_loss: 0.8910 - val_acc: 0.6655\n",
      "Epoch 50/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.7373 - acc: 0.7354 - val_loss: 0.9593 - val_acc: 0.6636\n",
      "Epoch 51/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.7557 - acc: 0.7246 - val_loss: 0.7935 - val_acc: 0.7291\n",
      "Epoch 52/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.7657 - acc: 0.7263 - val_loss: 0.7628 - val_acc: 0.7382\n",
      "Epoch 53/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.7206 - acc: 0.7480 - val_loss: 0.8513 - val_acc: 0.6982\n",
      "Epoch 54/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.7119 - acc: 0.7513 - val_loss: 1.6547 - val_acc: 0.5818\n",
      "Epoch 55/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6899 - acc: 0.7595 - val_loss: 0.8809 - val_acc: 0.6945\n",
      "Epoch 56/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.7117 - acc: 0.7461 - val_loss: 0.7766 - val_acc: 0.7291\n",
      "Epoch 57/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6945 - acc: 0.7358 - val_loss: 0.7945 - val_acc: 0.7327\n",
      "Epoch 58/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6989 - acc: 0.7535 - val_loss: 0.9178 - val_acc: 0.6655\n",
      "Epoch 59/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6498 - acc: 0.7588 - val_loss: 0.9425 - val_acc: 0.6727\n",
      "Epoch 60/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.6855 - acc: 0.7526 - val_loss: 0.7694 - val_acc: 0.7418\n",
      "Epoch 61/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6494 - acc: 0.7705 - val_loss: 0.9071 - val_acc: 0.6982\n",
      "Epoch 62/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6343 - acc: 0.7711 - val_loss: 0.8044 - val_acc: 0.7055\n",
      "Epoch 63/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6268 - acc: 0.7728 - val_loss: 0.7344 - val_acc: 0.7400\n",
      "Epoch 64/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6476 - acc: 0.7687 - val_loss: 0.7387 - val_acc: 0.7200\n",
      "Epoch 65/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6096 - acc: 0.7805 - val_loss: 0.8222 - val_acc: 0.7473\n",
      "Epoch 66/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6472 - acc: 0.7722 - val_loss: 1.0516 - val_acc: 0.7109\n",
      "Epoch 67/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6000 - acc: 0.7879 - val_loss: 0.7321 - val_acc: 0.7436\n",
      "Epoch 68/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6051 - acc: 0.7873 - val_loss: 1.2818 - val_acc: 0.6509\n",
      "Epoch 69/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.6103 - acc: 0.7933 - val_loss: 0.9921 - val_acc: 0.6891\n",
      "Epoch 70/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5740 - acc: 0.7997 - val_loss: 0.8116 - val_acc: 0.7109\n",
      "Epoch 71/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5944 - acc: 0.8036 - val_loss: 0.9014 - val_acc: 0.6873\n",
      "Epoch 72/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5243 - acc: 0.8163 - val_loss: 1.1428 - val_acc: 0.6764\n",
      "Epoch 73/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5489 - acc: 0.8102 - val_loss: 0.8656 - val_acc: 0.7091\n",
      "Epoch 74/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5432 - acc: 0.8110 - val_loss: 2.1109 - val_acc: 0.5545\n",
      "Epoch 75/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.6005 - acc: 0.7944 - val_loss: 0.8934 - val_acc: 0.7418\n",
      "Epoch 76/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5565 - acc: 0.8081 - val_loss: 0.6817 - val_acc: 0.7655\n",
      "Epoch 77/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5497 - acc: 0.8108 - val_loss: 1.2435 - val_acc: 0.6345\n",
      "Epoch 78/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.5519 - acc: 0.8148 - val_loss: 0.9071 - val_acc: 0.7036\n",
      "Epoch 79/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5411 - acc: 0.8176 - val_loss: 0.6643 - val_acc: 0.7782\n",
      "Epoch 80/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4992 - acc: 0.8270 - val_loss: 1.3144 - val_acc: 0.6127\n",
      "Epoch 81/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5053 - acc: 0.8291 - val_loss: 0.9011 - val_acc: 0.7055\n",
      "Epoch 82/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.5513 - acc: 0.8194 - val_loss: 0.7327 - val_acc: 0.7564\n",
      "Epoch 83/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.5168 - acc: 0.8202 - val_loss: 0.7456 - val_acc: 0.7491\n",
      "Epoch 84/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.5283 - acc: 0.8264 - val_loss: 0.8870 - val_acc: 0.7091\n",
      "Epoch 85/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4593 - acc: 0.8496 - val_loss: 0.9213 - val_acc: 0.7018\n",
      "Epoch 86/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 0.4817 - acc: 0.8342 - val_loss: 0.7478 - val_acc: 0.7636\n",
      "Epoch 87/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4222 - acc: 0.8504 - val_loss: 0.8605 - val_acc: 0.7509\n",
      "Epoch 88/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4600 - acc: 0.8435 - val_loss: 0.7300 - val_acc: 0.7491\n",
      "Epoch 89/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.5004 - acc: 0.8314 - val_loss: 0.7606 - val_acc: 0.7273\n",
      "Epoch 90/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4898 - acc: 0.8463 - val_loss: 0.8303 - val_acc: 0.7800\n",
      "Epoch 91/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4529 - acc: 0.8386 - val_loss: 0.7800 - val_acc: 0.7600\n",
      "Epoch 92/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4557 - acc: 0.8519 - val_loss: 0.6688 - val_acc: 0.7800\n",
      "Epoch 93/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4110 - acc: 0.8585 - val_loss: 0.8927 - val_acc: 0.7200\n",
      "Epoch 94/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4221 - acc: 0.8597 - val_loss: 0.7421 - val_acc: 0.7491\n",
      "Epoch 95/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4530 - acc: 0.8498 - val_loss: 0.9259 - val_acc: 0.7291\n",
      "Epoch 96/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4166 - acc: 0.8608 - val_loss: 0.7341 - val_acc: 0.7582\n",
      "Epoch 97/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4461 - acc: 0.8495 - val_loss: 0.7343 - val_acc: 0.7855\n",
      "Epoch 98/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4116 - acc: 0.8572 - val_loss: 0.8059 - val_acc: 0.7709\n",
      "Epoch 99/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4277 - acc: 0.8605 - val_loss: 2.0026 - val_acc: 0.6200\n",
      "Epoch 100/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4023 - acc: 0.8715 - val_loss: 0.7641 - val_acc: 0.7345\n",
      "Epoch 101/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 118ms/step - loss: 0.4151 - acc: 0.8605 - val_loss: 1.0898 - val_acc: 0.7182\n",
      "Epoch 102/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.4114 - acc: 0.8576 - val_loss: 0.6969 - val_acc: 0.7636\n",
      "Epoch 103/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.4157 - acc: 0.8637 - val_loss: 0.6803 - val_acc: 0.7818\n",
      "Epoch 104/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3875 - acc: 0.8650 - val_loss: 0.8286 - val_acc: 0.7455\n",
      "Epoch 105/250\n",
      "Learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3691 - acc: 0.8780 - val_loss: 0.8040 - val_acc: 0.7509\n",
      "Epoch 106/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3841 - acc: 0.8745 - val_loss: 0.7300 - val_acc: 0.7600\n",
      "Epoch 107/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3660 - acc: 0.8762 - val_loss: 1.2431 - val_acc: 0.7055\n",
      "Epoch 108/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3657 - acc: 0.8736 - val_loss: 0.8302 - val_acc: 0.7764\n",
      "Epoch 109/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3794 - acc: 0.8738 - val_loss: 0.7657 - val_acc: 0.7745\n",
      "Epoch 110/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3666 - acc: 0.8759 - val_loss: 1.7590 - val_acc: 0.6309\n",
      "Epoch 111/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 0.3680 - acc: 0.8745 - val_loss: 0.8403 - val_acc: 0.7564\n",
      "Epoch 112/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3432 - acc: 0.8854 - val_loss: 0.9651 - val_acc: 0.7236\n",
      "Epoch 113/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3908 - acc: 0.8748 - val_loss: 0.8616 - val_acc: 0.7327\n",
      "Epoch 114/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3497 - acc: 0.8919 - val_loss: 2.2401 - val_acc: 0.6273\n",
      "Epoch 115/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3783 - acc: 0.8801 - val_loss: 0.9172 - val_acc: 0.7036\n",
      "Epoch 116/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3191 - acc: 0.8880 - val_loss: 0.8992 - val_acc: 0.7109\n",
      "Epoch 117/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3362 - acc: 0.8842 - val_loss: 1.8278 - val_acc: 0.6364\n",
      "Epoch 118/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.3132 - acc: 0.8995 - val_loss: 1.1228 - val_acc: 0.7200\n",
      "Epoch 119/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3411 - acc: 0.8918 - val_loss: 0.8322 - val_acc: 0.7673\n",
      "Epoch 120/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.3592 - acc: 0.8889 - val_loss: 0.7366 - val_acc: 0.7764\n",
      "Epoch 121/250\n",
      "Learning rate:  0.0001\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.2987 - acc: 0.9019 - val_loss: 1.0110 - val_acc: 0.7455\n",
      "Epoch 122/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.2401 - acc: 0.9179 - val_loss: 0.7170 - val_acc: 0.7800\n",
      "Epoch 123/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1559 - acc: 0.9476 - val_loss: 0.6888 - val_acc: 0.7855\n",
      "Epoch 124/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1732 - acc: 0.9378 - val_loss: 0.6713 - val_acc: 0.8018\n",
      "Epoch 125/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1580 - acc: 0.9425 - val_loss: 0.7028 - val_acc: 0.7982\n",
      "Epoch 126/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 0.1487 - acc: 0.9497 - val_loss: 0.7007 - val_acc: 0.7909\n",
      "Epoch 127/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1653 - acc: 0.9460 - val_loss: 0.7196 - val_acc: 0.7909\n",
      "Epoch 128/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1315 - acc: 0.9586 - val_loss: 0.7233 - val_acc: 0.7927\n",
      "Epoch 129/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1464 - acc: 0.9458 - val_loss: 0.7055 - val_acc: 0.7909\n",
      "Epoch 130/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1600 - acc: 0.9386 - val_loss: 0.7026 - val_acc: 0.8018\n",
      "Epoch 131/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1486 - acc: 0.9479 - val_loss: 0.7176 - val_acc: 0.8036\n",
      "Epoch 132/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1389 - acc: 0.9556 - val_loss: 0.7385 - val_acc: 0.7945\n",
      "Epoch 133/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1359 - acc: 0.9549 - val_loss: 0.6751 - val_acc: 0.8055\n",
      "Epoch 134/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1456 - acc: 0.9518 - val_loss: 0.6870 - val_acc: 0.8018\n",
      "Epoch 135/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1380 - acc: 0.9532 - val_loss: 0.7089 - val_acc: 0.8091\n",
      "Epoch 136/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1387 - acc: 0.9541 - val_loss: 0.6901 - val_acc: 0.8000\n",
      "Epoch 137/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1418 - acc: 0.9494 - val_loss: 0.7249 - val_acc: 0.7909\n",
      "Epoch 138/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1438 - acc: 0.9502 - val_loss: 0.6748 - val_acc: 0.8018\n",
      "Epoch 139/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1393 - acc: 0.9546 - val_loss: 0.7092 - val_acc: 0.8018\n",
      "Epoch 140/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1476 - acc: 0.9533 - val_loss: 0.6720 - val_acc: 0.8036\n",
      "Epoch 141/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1390 - acc: 0.9500 - val_loss: 0.7076 - val_acc: 0.7909\n",
      "Epoch 142/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1541 - acc: 0.9505 - val_loss: 0.7167 - val_acc: 0.7836\n",
      "Epoch 143/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1730 - acc: 0.9419 - val_loss: 0.7136 - val_acc: 0.8000\n",
      "Epoch 144/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 0.1359 - acc: 0.9559 - val_loss: 0.6762 - val_acc: 0.8073\n",
      "Epoch 145/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1213 - acc: 0.9556 - val_loss: 0.7264 - val_acc: 0.8091\n",
      "Epoch 146/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1295 - acc: 0.9576 - val_loss: 0.6938 - val_acc: 0.8091\n",
      "Epoch 147/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1249 - acc: 0.9615 - val_loss: 0.6722 - val_acc: 0.8091\n",
      "Epoch 148/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1327 - acc: 0.9543 - val_loss: 0.7220 - val_acc: 0.7891\n",
      "Epoch 149/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1639 - acc: 0.9496 - val_loss: 0.7302 - val_acc: 0.8055\n",
      "Epoch 150/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1256 - acc: 0.9579 - val_loss: 0.6995 - val_acc: 0.8000\n",
      "Epoch 151/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1266 - acc: 0.9547 - val_loss: 0.6861 - val_acc: 0.8164\n",
      "Epoch 152/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1466 - acc: 0.9546 - val_loss: 0.7179 - val_acc: 0.8018\n",
      "Epoch 153/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1331 - acc: 0.9582 - val_loss: 0.6653 - val_acc: 0.7964\n",
      "Epoch 154/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 0.1425 - acc: 0.9496 - val_loss: 0.6821 - val_acc: 0.8182\n",
      "Epoch 155/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1260 - acc: 0.9562 - val_loss: 0.7255 - val_acc: 0.8055\n",
      "Epoch 156/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1291 - acc: 0.9523 - val_loss: 0.7090 - val_acc: 0.7964\n",
      "Epoch 157/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1369 - acc: 0.9574 - val_loss: 0.6950 - val_acc: 0.8018\n",
      "Epoch 158/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1432 - acc: 0.9550 - val_loss: 0.7175 - val_acc: 0.7927\n",
      "Epoch 159/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1250 - acc: 0.9595 - val_loss: 0.7192 - val_acc: 0.8127\n",
      "Epoch 160/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1244 - acc: 0.9608 - val_loss: 0.7192 - val_acc: 0.8091\n",
      "Epoch 161/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1168 - acc: 0.9594 - val_loss: 0.7126 - val_acc: 0.7927\n",
      "Epoch 162/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1323 - acc: 0.9568 - val_loss: 0.7106 - val_acc: 0.7909\n",
      "Epoch 163/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1200 - acc: 0.9583 - val_loss: 0.7001 - val_acc: 0.7982\n",
      "Epoch 164/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1177 - acc: 0.9610 - val_loss: 0.6840 - val_acc: 0.8091\n",
      "Epoch 165/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1369 - acc: 0.9544 - val_loss: 0.7151 - val_acc: 0.7909\n",
      "Epoch 166/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1068 - acc: 0.9617 - val_loss: 0.6747 - val_acc: 0.8164\n",
      "Epoch 167/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1218 - acc: 0.9601 - val_loss: 0.6898 - val_acc: 0.8000\n",
      "Epoch 168/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1167 - acc: 0.9626 - val_loss: 0.6810 - val_acc: 0.8091\n",
      "Epoch 169/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1272 - acc: 0.9499 - val_loss: 0.7218 - val_acc: 0.8073\n",
      "Epoch 170/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 121ms/step - loss: 0.1243 - acc: 0.9567 - val_loss: 0.7331 - val_acc: 0.7891\n",
      "Epoch 171/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1294 - acc: 0.9537 - val_loss: 0.7304 - val_acc: 0.7945\n",
      "Epoch 172/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1011 - acc: 0.9630 - val_loss: 0.7497 - val_acc: 0.7982\n",
      "Epoch 173/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1142 - acc: 0.9597 - val_loss: 0.7001 - val_acc: 0.8018\n",
      "Epoch 174/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1192 - acc: 0.9583 - val_loss: 0.7180 - val_acc: 0.8018\n",
      "Epoch 175/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1193 - acc: 0.9650 - val_loss: 0.7546 - val_acc: 0.7982\n",
      "Epoch 176/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.1134 - acc: 0.9594 - val_loss: 0.7255 - val_acc: 0.8018\n",
      "Epoch 177/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1093 - acc: 0.9636 - val_loss: 0.7257 - val_acc: 0.7909\n",
      "Epoch 178/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 119ms/step - loss: 0.1142 - acc: 0.9603 - val_loss: 0.7493 - val_acc: 0.8000\n",
      "Epoch 179/250\n",
      "Learning rate:  1e-05\n",
      "69/68 [==============================] - 8s 120ms/step - loss: 0.0988 - acc: 0.9636 - val_loss: 0.7272 - val_acc: 0.8073\n",
      "Epoch 180/250\n",
      "Learning rate:  1e-05\n",
      "31/68 [============>.................] - ETA: 4s - loss: 0.1246 - acc: 0.9577"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3e28f8272754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2200\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2919\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2922\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2923\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2879\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(train_imgs, y_train, batch_size=32),steps_per_epoch= 2200 / 32, epochs=250,validation_data=(test_imgs,y_test),callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "80f0b98ab5f65265d473088e79935aa48ee61007"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del train_imgs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "fd0a98183e00a65dc91932c99749ead42c323130"
   },
   "outputs": [],
   "source": [
    "# dim = 256\n",
    "\n",
    "# kernel_filter = 1/12. * np.array([\\\n",
    "#             [-1,  2,  -2,  2, -1],  \\\n",
    "#             [ 2, -6,   8, -6,  2],  \\\n",
    "#             [-2,  8, -12,  8, -2],  \\\n",
    "#             [ 2, -6,   8, -6,  2],  \\\n",
    "#             [-1,  2,  -2,  2, -1]])\n",
    "\n",
    "\n",
    "# test_imgs = []\n",
    "# for file in tqdm_notebook(x_test_files):\n",
    "#     img = cv2.imread(file)\n",
    "#     center_x = img.shape[0]//2\n",
    "#     center_y = img.shape[1]//2 \n",
    "#     cropped_img = img[center_x-dim//2:center_x+dim//2, center_y-dim//2:center_y+dim//2, : ]\n",
    "    \n",
    "#     cropped_img = cv2.filter2D(cropped_img.astype(np.float32),-1,kernel_filter)    \n",
    "#     test_imgs.append(cropped_img)\n",
    "#     del file,img,center_x,center_y,cropped_img\n",
    "#     gc.collect()\n",
    "\n",
    "# test_imgs = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "80249ca0bdd8227ba16aec0bd435976b0fe87037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550/550 [==============================] - 1s 2ms/step\n",
      "Test loss: 0.5598801576007496\n",
      "Test accuracy: 0.8199999997832559\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_imgs,y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "79a92583e98d348fdbe6a686f0b475d348bea67e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del test_imgs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f856d9355a071016b32b1be1d449be25b6349ca5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
