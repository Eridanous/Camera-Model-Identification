{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport glob\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport time\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation,Dropout,BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "['train', 'test', 'sample_submission.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0266afb2d5d0c48a9399c4e78944120c3dc87522"
      },
      "cell_type": "code",
      "source": "data = '../input/'\ntrain_files = sorted(glob.glob(data + 'train/*/*'))\n# test_path = sorted(glob.glob(data + 'test/*'))\n\nlabels = ['HTC-1-M7', 'iPhone-4s', 'iPhone-6', 'LG-Nexus-5x', 'Motorola-Droid-Maxx', \n         'Motorola-Nexus-6', 'Motorola-X', 'Samsung-Galaxy-Note3', 'Samsung-Galaxy-S4',\n         'Sony-NEX-7'] \nAll_labels = [labels.index(file.split('/')[-2]) for file in train_files] # TO BE CHANGED!!!!!!!\n\nx_train_files, x_test_files, y_train_files, y_test_files = train_test_split(train_files,All_labels,test_size = 0.2, shuffle = True,random_state = 42)\n\n# y_train = keras.utils.to_categorical(y_train_files, len(labels)) # one hot vector\ny_test = keras.utils.to_categorical(y_test_files, len(labels)) # one hot vector",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0e9f51667d2506f682ef4b096702075b070fbe2"
      },
      "cell_type": "code",
      "source": "# y_train_files\nlen(y_train_files)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "2200"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1abd73babae5d3cfef95f55c1fc31cf1e7ef6fd3"
      },
      "cell_type": "code",
      "source": "crdim = 256\n\nkernel_filter = 1/12. * np.array([\\\n            [-1,  2,  -2,  2, -1],  \\\n            [ 2, -6,   8, -6,  2],  \\\n            [-2,  8, -12,  8, -2],  \\\n            [ 2, -6,   8, -6,  2],  \\\n            [-1,  2,  -2,  2, -1]])\n\n\n\n\n\n\ntrain_imgs = []\ncount_file = -1\ny_augm = [] # augmented labels\nfor file in tqdm_notebook(x_train_files):\n    img = cv2.imread(file)\n    x,y = img.shape[:2]\n\n    count_file += 1 # number of img out of 2750 (or len of train set)\n    img_label = y_train_files[count_file]    \n    \n\n    x,y = img.shape[:2]\n\n    xpos = []\n#     xpos.append([0,crdim])\n    xpos.append([x//2-crdim//2,x//2+crdim//2])\n#     xpos.append([x-crdim,x])\n\n    ypos = []\n    ypos.append([0,crdim])\n    ypos.append([y//2-crdim//2,y//2+crdim//2])\n#     ypos.append([y-crdim,y])\n\n    cr_imgs = []\n    for i in xpos:\n        for j in ypos:\n            crimg = img[i[0]:i[1], j[0]:j[1],:]\n#             crimg = cv2.filter2D(crimg.astype(np.float32),-1,kernel_filter)\n            train_imgs.append(crimg)\n            \n    for t in range(len(xpos)*len(ypos)): # total crops\n        y_augm.append(y_train_files[count_file]) # augment labels\n\n            \n    del file,img,crimg\n    gc.collect()\n\ntrain_imgs = np.array(train_imgs)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=2200), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d6020f652c84c58b9f292955d4faf6a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7fff41645a1ddb48ee82b9904d63437d13b4fc25"
      },
      "cell_type": "code",
      "source": "dim = 256\n\nkernel_filter = 1/12. * np.array([\\\n            [-1,  2,  -2,  2, -1],  \\\n            [ 2, -6,   8, -6,  2],  \\\n            [-2,  8, -12,  8, -2],  \\\n            [ 2, -6,   8, -6,  2],  \\\n            [-1,  2,  -2,  2, -1]])\n\n\ntest_imgs = []\nfor file in tqdm_notebook(x_test_files):\n    img = cv2.imread(file)\n    center_x = img.shape[0]//2\n    center_y = img.shape[1]//2 \n    cropped_img = img[center_x-dim//2:center_x+dim//2, center_y-dim//2:center_y+dim//2, : ]\n    \n    cropped_img = cv2.filter2D(cropped_img.astype(np.float32),-1,kernel_filter)    \n    test_imgs.append(cropped_img)\n    del file,img,center_x,center_y,cropped_img\n    gc.collect()\n\ntest_imgs = np.array(test_imgs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "893b58070303715844bdb2c137768f1574aff07a"
      },
      "cell_type": "code",
      "source": "y_train = keras.utils.to_categorical(y_augm, len(labels)) # one hot vector",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4135d382343e0d538eae942f63d5137f609f4dea"
      },
      "cell_type": "code",
      "source": "def myFunc(img):\n    kernel_filter = 1/12. * np.array([\\\n            [-1,  2,  -2,  2, -1],  \\\n            [ 2, -6,   8, -6,  2],  \\\n            [-2,  8, -12,  8, -2],  \\\n            [ 2, -6,   8, -6,  2],  \\\n            [-1,  2,  -2,  2, -1]])\n\n    pro_img = cv2.filter2D(img,-1,kernel_filter)\n    return pro_img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip = True,preprocessing_function = myFunc)\n# datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip = True)\ndatagen.fit(train_imgs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "821bb113b696fbb3cd69b4215bb9ad71fb943d0e"
      },
      "cell_type": "code",
      "source": "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\n\ndef lr_schedule(epoch):\n    \"\"\"Learning Rate Schedule\n\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n\n    # Arguments\n        epoch (int): The number of epochs\n\n    # Returns\n        lr (float32): learning rate\n    \"\"\"\n    lr = 0.0001\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [lr_reducer, lr_scheduler]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f334cac5244bb3605729d56a767592aacbbd0e0"
      },
      "cell_type": "code",
      "source": "model=Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3),strides=(2, 2), input_shape=(256, 256, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3),strides=(2, 2) ))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(32, kernel_size=(3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\n# opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\nopt = keras.optimizers.rmsprop(lr=lr_schedule(0), decay=1e-6)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6bca9c8b21c49e5fb2d7266cca8c899a3bccb55f",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "model.fit_generator(datagen.flow(train_imgs, y_train, batch_size=32), validation_data=(test_imgs,y_test) ,steps_per_epoch= None, epochs=200, callbacks=callbacks) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fce899af7951121558580c9f9b246cf283daa1ac"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "328f6aba290b6dba713c8116fa60145093d1f352"
      },
      "cell_type": "code",
      "source": "scores = model.evaluate(test_imgs,y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a182870a196faeed9fb1515f59b94f20321c1a9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c1b29e192f989885be01a07fa4daff434858949"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a91f664fe16f0aa4a9c55d79d7c01c3661531da2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2610c501314e8331f150cb01e44b0b53baee35bb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "17b55c90a04fdb711a255a89726c149df04c758b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b510fbf3a38fc388decb1eed8b841c6a865670e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67009753d5ec774db60d56633a7a507f79a6fd4f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b8428f5e4d4bbcfc3f2f8a4c3ed70f37dc42455"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b371af1b1df316f9cb93e2691ff75e01a536e3e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}